{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "1bd83264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install newsapi-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "66ee2669",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from newsapi import NewsApiClient\n",
    "from tqdm import tqdm\n",
    "\n",
    "from keybert import KeyBERT\n",
    "\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from itertools import chain\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "b5db74dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# api request를 정하는 부분으로 신중하게 확인할\n",
    "from_date = '2023-03-23'\n",
    "to_date = '2023-03-23'\n",
    "query = 'finance OR banking OR economy'\n",
    "pages = range(1,6) # 무료 api는 일일당 5page가 최대."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "e8dd3c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 환경 설정\n",
    "cwd = os.getcwd()\n",
    "main_path = cwd + '/' + query \n",
    "\n",
    "def createFolder(directory):\n",
    "    try:\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "    except OSError:\n",
    "        print ('Error: Creating directory. ' +  directory)\n",
    "\n",
    "createFolder(main_path)\n",
    "createFolder(main_path + '/' + 'dataByDate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "0bac69a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 수집(api)\n",
    "f=open(r\"C:\\Users\\NH\\Desktop\\newsapi_api_ key.txt\",\"rt\")\n",
    "while True:\n",
    "    api_key = f.read() \n",
    "    break\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "c0a44b91",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    },
    {
     "ename": "NewsAPIException",
     "evalue": "{'status': 'error', 'code': 'rateLimited', 'message': 'You have made too many requests recently. Developer accounts are limited to 100 requests over a 24 hour period (50 requests available every 12 hours). Please upgrade to a paid plan if you need more requests.'}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNewsAPIException\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17512\\2759716796.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mpage\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpages\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     all_articles = newsapi.get_everything(q=query,\n\u001b[0m\u001b[0;32m      9\u001b[0m                                           \u001b[0mfrom_param\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfrom_date\u001b[0m \u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m                                           \u001b[0mto\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mto_date\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\newsapi\\newsapi_client.py\u001b[0m in \u001b[0;36mget_everything\u001b[1;34m(self, q, qintitle, sources, domains, exclude_domains, from_param, to, language, sort_by, page, page_size)\u001b[0m\n\u001b[0;32m    332\u001b[0m         \u001b[1;31m# Check Status of Request\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    333\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcodes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mok\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 334\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mNewsAPIException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    335\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    336\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNewsAPIException\u001b[0m: {'status': 'error', 'code': 'rateLimited', 'message': 'You have made too many requests recently. Developer accounts are limited to 100 requests over a 24 hour period (50 requests available every 12 hours). Please upgrade to a paid plan if you need more requests.'}"
     ]
    }
   ],
   "source": [
    "# api 횟수가 차감되는 부분으로 신중히 돌릴것\n",
    "newsapi = NewsApiClient(api_key=api_key)\n",
    "news = []\n",
    "urls = []\n",
    "dates = []\n",
    "for page in pages:\n",
    "    print(page)\n",
    "    all_articles = newsapi.get_everything(q=query,\n",
    "                                          from_param=from_date ,\n",
    "                                          to=to_date,\n",
    "                                          language='en',\n",
    "                                          sort_by='relevancy',\n",
    "                                          page=page)\n",
    "\n",
    "    for article in all_articles['articles']:\n",
    "        \n",
    "        title = article['title']\n",
    "        description = article['description']\n",
    "        content = '. '.join([title,description]) if description != None else ''\n",
    "        \n",
    "        url = article['url']\n",
    "        \n",
    "        publishedAt = article['publishedAt'][:10]\n",
    "        \n",
    "        news.append(content)\n",
    "        urls.append(url)\n",
    "        dates.append(publishedAt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db8f20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 키워드 추출\n",
    "\n",
    "def doc2key(content,kw_model):\n",
    "    \n",
    "    keywords = kw_model.extract_keywords(content, keyphrase_ngram_range=(1, 1), use_mmr=True,diversity=0.7,stop_words='english', top_n=10)\n",
    "    \n",
    "    keywords = [a[0] for a in keywords if a[1] >= 0.25 ]\n",
    "    \n",
    "    return keywords\n",
    "\n",
    "kw_model = KeyBERT(model='all-MiniLM-L6-v2')\n",
    "keywords = []\n",
    "for content in tqdm(news):\n",
    "    keyword = doc2key(content,kw_model)\n",
    "    keywords.append(keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fed73ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# html에서 추출한 정보를 dataframe으로 만들고 저장.\n",
    "data = pd.DataFrame({'date':dates,'news':news,'url':urls,'keyword':keywords})\n",
    "\n",
    "name = \"dataByDate_{}_{}.pickle\".format(from_date,to_date)\n",
    "name = name.replace('/','.')\n",
    "with open(main_path + '/' + 'dataByDate/' + name,'wb') as f:\n",
    "    pickle.dump(data,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7562df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 키워드 카운트\n",
    "DataCountByDay = pd.DataFrame(Counter(list(chain(*data['keyword'].values))),index = [from_date])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2d0feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "DataCountByDay = DataCountByDay.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0f57d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 워드 클라우드\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "from matplotlib.pyplot import figure\n",
    "from wordcloud import (WordCloud, get_single_color_func)\n",
    "import numpy as np\n",
    "def DrawPointColoredWC(tags,title,cwd,searching_word, drop_list=[], color = '#00ff00', pointed_list=[]):\n",
    "    color_to_words = {\n",
    "        color : pointed_list\n",
    "    }\n",
    "\n",
    "    use_tags = tags.drop(drop_list, errors = 'ignore')\n",
    "    wc = WordCloud(font_path='C:/Windows/Fonts/malgun',background_color=\"white\",width=1600, height=800,random_state = 1)\n",
    "\n",
    "    default_color = 'black'\n",
    "    grouped_color_func = GroupedColorFunc(color_to_words, default_color)\n",
    "\n",
    "    cloud = wc.generate_from_frequencies(dict(use_tags))\n",
    "    wc.recolor(color_func=grouped_color_func)\n",
    "\n",
    "    figure(dpi=1200)\n",
    "    figure(figsize=[12,8])\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(wc, interpolation=\"bilinear\")\n",
    "    plt.savefig(cwd + '/' + searching_word + '/'+ title + ' 강조'+'.pdf')\n",
    "    plt.show()\n",
    "    \n",
    "class SimpleGroupedColorFunc(object):\n",
    "    \"\"\"Create a color function object which assigns EXACT colors\n",
    "       to certain words based on the color to words mapping\n",
    "\n",
    "       Parameters\n",
    "       ----------\n",
    "       color_to_words : dict(str -> list(str))\n",
    "         A dictionary that maps a color to the list of words.\n",
    "\n",
    "       default_color : str\n",
    "         Color that will be assigned to a word that's not a member\n",
    "         of any value from color_to_words.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, color_to_words, default_color):\n",
    "        self.word_to_color = {word: color\n",
    "                              for (color, words) in color_to_words.items()\n",
    "                              for word in words}\n",
    "\n",
    "        self.default_color = default_color\n",
    "\n",
    "    def __call__(self, word, **kwargs):\n",
    "        return self.word_to_color.get(word, self.default_color)\n",
    "\n",
    "\n",
    "class GroupedColorFunc(object):\n",
    "    \"\"\"Create a color function object which assigns DIFFERENT SHADES of\n",
    "       specified colors to certain words based on the color to words mapping.\n",
    "\n",
    "       Uses wordcloud.get_single_color_func\n",
    "\n",
    "       Parameters\n",
    "       ----------\n",
    "       color_to_words : dict(str -> list(str))\n",
    "         A dictionary that maps a color to the list of words.\n",
    "\n",
    "       default_color : str\n",
    "         Color that will be assigned to a word that's not a member\n",
    "         of any value from color_to_words.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, color_to_words, default_color):\n",
    "        self.color_func_to_words = [\n",
    "            (get_single_color_func(color), set(words))\n",
    "            for (color, words) in color_to_words.items()]\n",
    "\n",
    "        self.default_color_func = get_single_color_func(default_color)\n",
    "\n",
    "    def get_color_func(self, word):\n",
    "        \"\"\"Returns a single_color_func associated with the word\"\"\"\n",
    "        try:\n",
    "            color_func = next(\n",
    "                color_func for (color_func, words) in self.color_func_to_words\n",
    "                if word in words)\n",
    "        except StopIteration:\n",
    "            color_func = self.default_color_func\n",
    "\n",
    "        return color_func\n",
    "\n",
    "    def __call__(self, word, **kwargs):\n",
    "        return self.get_color_func(word)(word, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5d0f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최대 키워드 수, 지울 단어, 강조할 단어 지정\n",
    "num_exp = 100\n",
    "drop_list = [np.nan,'2023','2022','thomson','httpswww','review','review terms','sure','reuters','terms','theres','happen','cookies','content','javascript','browser','supports javascript','did happen','loading information']\n",
    "num = num_exp + len(drop_list)\n",
    "color_to_words = {\n",
    "    '#00ff00': []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51239ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그림 그리기 및 저장\n",
    "tags = DataCountByDay.sort_values(by = from_date, ascending = False)[1:num+1][from_date]\n",
    "tags = tags.drop(drop_list, errors = 'ignore')[:num_exp]\n",
    "print('{}에서 {}까지 키워드 출현 빈도 순 상위 {}개 입니다'.format(from_date,to_date,num_exp))\n",
    "wc = WordCloud(font_path='C:/Windows/Fonts/malgun',background_color=\"white\",width=1600, height=800,random_state = 1)\n",
    "# default_color = 'black'\n",
    "# grouped_color_func = GroupedColorFunc(color_to_words, default_color)\n",
    "\n",
    "cloud = wc.generate_from_frequencies(dict(tags))\n",
    "# wc.recolor(color_func=grouped_color_func)\n",
    "\n",
    "figure(dpi=1200)\n",
    "title = '대상기간_최대출현_키워드_{}개'.format(str(len(tags)))\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(wc, interpolation=\"bilinear\")\n",
    "plt.savefig(cwd + '/' + query + '/'+ title + from_date + '.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0874adac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 일주일 평균 대비 상승 키워드 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ce3cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# 뉴스 검색기능(구현예정)\n",
    "keyword = 'savings'\n",
    "\n",
    "tmp = []\n",
    "for i in keyword_long_data['keyword']:\n",
    "    if keyword in i:\n",
    "        tmp.append(True)\n",
    "    else:\n",
    "        tmp.append(False)\n",
    "\n",
    "for url in url_long_data[tmp]['url']:\n",
    "    print(url)\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
